# ğŸ›³ï¸ Titanic - Machine Learning from Disaster

Este projeto faz parte do desafio do Kaggle **[Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)**, que propÃµe prever a sobrevivÃªncia de passageiros com base em dados como classe, idade, sexo, nÃºmero de familiares a bordo, entre outros.

---

## ğŸ¯ Objetivo

Utilizar modelos de aprendizado de mÃ¡quina para prever quem sobreviveu ao naufrÃ¡gio do Titanic com base em variÃ¡veis do conjunto de dados fornecido.

---

## ğŸ§  Modelo Utilizado

Foi utilizada uma **Ã¡rvore de decisÃ£o com profundidade igual a 1**, o que significa que o modelo toma a decisÃ£o com base em apenas uma divisÃ£o (split) nos dados.

### ğŸ“Œ Motivo da Escolha
A ideia era explorar a simplicidade do modelo e observar atÃ© que ponto uma decisÃ£o baseada em **apenas uma variÃ¡vel** poderia prever corretamente os dados de treino.

---

## âœ… Resultados

- O modelo obteve **100% de acurÃ¡cia no conjunto de treino**.
- Como era esperado, por se tratar de um modelo extremamente simples, a **generalizaÃ§Ã£o em dados fora do treino pode ser fraca**, mas isso reforÃ§a o estudo de **overfitting** e a importÃ¢ncia da **validaÃ§Ã£o cruzada**.

---

## ğŸ—‚ï¸ Estrutura do Projeto

- titanic_decision_tree.ipynb # Notebook com o treinamento do modelo
- train.csv # Dados de treino
- test.csv # Dados de teste
- gender_submission.csv # Resultados esperados do Kaggle
- README.md # Este arquivo

---

## âš™ï¸ Tecnologias e Bibliotecas

- Python 3
- Pandas
- Scikit-learn
- Matplotlib / Seaborn (para anÃ¡lise exploratÃ³ria)

---

## ğŸ“š LiÃ§Ãµes Aprendidas

- Modelos simples como Ã¡rvores rasas podem se ajustar perfeitamente ao treino, mas isso nÃ£o garante boa performance em produÃ§Ã£o.
- A variÃ¡vel mais discriminativa foi suficiente para separar as classes nos dados de treino, mas isso tende a mudar com dados reais ou mais complexos.

---

## âœ¨ PrÃ³ximos Passos

- Aplicar validaÃ§Ã£o cruzada para evitar overfitting.
- Testar outros modelos mais robustos como Random Forest ou XGBoost.
- Realizar engenharia de atributos para melhorar a performance nos dados de teste.

---

> ğŸš¢ "Not all those who wander are lost â€“ unless they are aboard the Titanic."
